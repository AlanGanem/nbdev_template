{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DELETE THIS SESSION AFTER EDITING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n",
       "//DELETE THIS CELL AFTER EDITING THE NOTEBOOK\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n",
    "//DELETE THIS CELL AFTER EDITING THE NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(f'{nb_name} template has been left inaltered. Delete notebook or alter file and delete first cell')\n",
    "#DELETE THIS CELL AFTER EDITING THE NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import module packages for exemplification in readme/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import parts of your code in order to show examples\n",
    "from src.load import *\n",
    "from src.preprocess import *\n",
    "from src.build_features import *\n",
    "from src.fit import *\n",
    "from src.transform import *\n",
    "from src.validate import *\n",
    "from src.main import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# < Analytics Projetct Name >\n",
    "\n",
    "The goal of the project is to ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checklist\n",
    "\n",
    "Mark which tasks have been performed\n",
    "\n",
    "- [ ] **Summary:** you have included a description, usage, output, accuracy and metadata of your model.\n",
    "- [ ] **Pre-processing:** you have applied pre-processing to your data and this function is reproducible to new datasets.\n",
    "- [ ] **Feature selection:** you have performed feature selection while modeling.\n",
    "- [ ] **Modeling dataset creation:** you have well-defined and reproducible code to generate a modeling dataset that reproduces the behavior of the target dataset.This pipeline is also applicable to generate the deploy dataset.\n",
    "- [ ] **Model selection:** you have chosen a suitable model according to the project specification.\n",
    "- [ ] **Model validation:** you have validated your model according to the project specification.\n",
    "- [ ] **Model optimization:** you have defined functions to optimize hyper-parameters and they are reproducible.\n",
    "- [ ] **Peer-review:** your code and results have been verified by your colleagues and pre-approved by them.\n",
    "- [ ] **Acceptance:** this model report has been accepted by the Data Science Manager. State name and date.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The model is designed to ... (state a simple sentence here to indicate what your model does)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "Describe step-by-step what should be done to run the algorithm, as in the example below:\n",
    "\n",
    "1.\tDownload the database from `<path_to_file>` and place it on an acessible folder in your machine\n",
    "2.\tClone this repository to your machine\n",
    "3.\tUpdate the `path` variable in main, to the path chosen on step 1. \n",
    "3.\tMake sure Python 3.6 is installed on your machine\n",
    "4.\tInstall all libraries on `requirements.txt` using the command:\n",
    "\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "5.\tRun the command `python src/main.py` \n",
    "6.\tCheck the results on the `output` directory\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "Clarify what are the files generated as output, with their names, paths and a brief description of the data structure (in case it is a CSV for example)\n",
    "\n",
    "Example:\n",
    "\n",
    "The model outputs a list called `<name>.csv` onto `<name>` and contains the following variables:\n",
    "\n",
    "- var1\n",
    "- var2\n",
    "- var3\n",
    "- var4\n",
    "- var5\n",
    "- var6\n",
    "\n",
    "In the future, the Score variable (from the Credit risk algorithm) shall also be automatically merged onto the output file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Metadata](docs/project_metadata.json)\n",
    "\n",
    "Here you should go the project metadata dictionary (written in JSON), as the file describes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics\n",
    "\n",
    "The project will be followed by a dashboard, available as a source code on this repo.\n",
    "The model is considered to be drifting when there are no visible distinction between clusters and/or when the KPI's are below the goal settled for the year.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "Here should be stated in a step-by-step way what was done in the pre-processing stage of the project.\n",
    "\n",
    "Example:\n",
    "\n",
    "1.\tExcluded readings with `<categories>` from `<rows>`: bad lines.\n",
    "2.\tLimited `<name>` to 4, which represents Bank payroll.\n",
    "3.\tExcludes `<name>` readings with more than 30 days in advance, in case they represent more 1%. \n",
    "4.\tStacked all invoices by customer with the mean of each variable (although in some cases other aggregation functions are used instead).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "Here should be explained how the features used for the model were selected, if any feature selection methodology was implemented and so on.\n",
    "\n",
    "Example:\n",
    "\n",
    "The feature selection methodology used was the Forward Selection. Also, some variables used on the Credit risk model were also considered, up until when the model reached its optimal performance. PCA and RFE did not present better results so far.\n",
    "\n",
    "**Features used**\n",
    "\n",
    "Here should be placed the features used to run the model entirely.\n",
    "\n",
    "Example:\n",
    "\n",
    "The features used to train both the clustering and classifier can be found under `models/config`, with the static variable `COLS_TO_TRAIN`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Here goes a better explanation on what algorithm was chosen and how does the complete model work.\n",
    "\n",
    "Example:\n",
    "\n",
    "To identify the clusters, the K-Means algorithm was chosen. A Random Forest Classifier from scikit-learn was then trained to predict the clusters for new customers and also customers with updated variable values. This pipeline has shown a good performance, running under 5 minutes and with satisfactory results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "\n",
    "Here should be stated a clarification on how it was decided to choose the running algorithm, and why not other ones. If any future implementations are envisioned, a brief statement should be made as well.\n",
    "\n",
    "Example:\n",
    "\n",
    "Although K-Medians normally performs better with outliers, K-Means still has shown more consistent results and therefore was decided to be used. K-Modes and K-Prototypes were also tested, for including categorical variables, but also had not either reached a good Silhouette Score or divided the data in a meaningful way. Spectral Clustering presented good results for a sample dataset, but has shown poor performance for the complete dataset, and still has to be studied for the next version. DBSCAN was considered, but since it neglects the outliers, it was then decided to be discarded. \n",
    "\n",
    "For the classification algorithm, Random Forest outperformed the Decision Tree and the XGBoost classifiers.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation\n",
    "\n",
    "A step-by-step explanation on what was done to choose the running model. The metrics measured to select them are also desired to be placed in the steps.\n",
    "\n",
    "Example:\n",
    "\n",
    "1.\tThe cluster numbers were chosen based on the Silhouette Score of 0,85.\n",
    "2.\tThe dataset was sampled to ensure the clustering consistency.\n",
    "3.\tThe clustered data was used as input for the Random Forest Classifier\n",
    "4.\tThe data was split into train and test (80/20).\n",
    "5.\tThe classifier reached the Accuracy Score of 0,96.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimization\n",
    "\n",
    "Here should be explained if any kind of optimization of the model was made.\n",
    "\n",
    "Example:\n",
    "\n",
    "The hyper-parameters `n_estimators` and `max_depth` were manually optimized for the classifier, although there is still room for improvement, through GridSearch, Genetic Algorithms, etc. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drifting and Retraining\n",
    "\n",
    "Here should be explained what are the necessary steps done in order to retrain the model, whenever some kind of drifting or underperformance is noticed.\n",
    "\n",
    "Example:\n",
    "\n",
    "Whenever drifting is noticed, lines 40, 41, 47, 56, 60 and 61 need to be uncommented on `main.py` before running the model. Once it is done, they need to be commented again. In future versions, this process is ought to be automated.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foreseen improvements\n",
    "\n",
    "If any future improvements are identified during any of the steps, they should be pointed out in this section.\n",
    "\n",
    "Example:\n",
    "\n",
    "- New features to be engineered in the next versions can potentially enhance clustering or recommendations. For example, it is still to be tested whether there is a type of customer that only pays back on a specific time of the month or week, and therefore they won't show in the recommendations list when they don't pay. \n",
    "\n",
    "- Treating the (many) outliers with some other measures, could potentially enhance predictions.\n",
    "\n",
    "- Automatically gather data and run the model is something to be worked on for future versions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
